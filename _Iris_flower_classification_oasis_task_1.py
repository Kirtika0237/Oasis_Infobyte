# -*- coding: utf-8 -*-
"""Oasis_TASK_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FMSXDsyiJV697MLaprZ7J8j9alncCraC

Task1: IRIS FLOWER CLASSIFICATION

Iris flower has three species; setosa, versicolor, and virginica, which differs according to their
measurements. Now assume that you have the measurements of the iris flowers according to
their species, and here your task is to train a machine learning model that can learn from the
measurements of the iris species and classify them.

Step 1:importing the data
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import datasets
from sklearn.cluster import KMeans

"""reading the dataset"""

#reading the iris dataset
df=pd.read_csv("Iris.csv")
df.head()

"""**Step 2: Visualising the data**"""

df.tail()

df.shape

df.columns

df['Species'].unique()

df.info()

df.describe()

"""This is an unsuperwised machine learning so we hate to drop the 2 columns Id and Species."""

iris=pd.DataFrame(df)
iris_df=iris.drop(columns=["Id","Species"])
iris_df.head()

"""Step 3:finding the optimum number of clusters

The **Elbow Method** is a visual approach used to determine the ideal ‘K’ (number of clusters) in K-means clustering. It operates by calculating the Within-Cluster Sum of Squares (WCSS), which is the total of the squared distances between data points and their cluster center.
"""

# Initialize the list
within_cluster_sum_of_squares = []

# Calculate the within-cluster sum of squares for different k values
cluster_range = range(1, 15)
for k in cluster_range:
    km = KMeans(n_clusters=k)
    km.fit(iris_df)
    within_cluster_sum_of_squares.append(km.inertia_)

"""Plotting the wcss against clusters range

"""

plt.plot(cluster_range,within_cluster_sum_of_squares,'go--',color='green')
plt.title("The elbow method")
plt.xlabel("Numbers of clusters")
plt.ylabel("Within_cluster_sum_of_squares")
plt.grid()
plt.show()

"""we can clearly says that the optimum clusters are found at elbow becuase the wcss doesn't decrease significantly with every iteration.

Step 4: Applying K-Means Clustering
"""

from sklearn.cluster import KMeans
model=KMeans(n_clusters=3,init='k-means++',max_iter=300,n_init=10,random_state=0)
predictions=model.fit_predict(iris_df)

"""Step 5:visualising the clusters"""

x=iris_df.iloc[:,[0,1,2,3]].values
plt.scatter(x[predictions==0,0],x[predictions==0,1],s=25,c='red',label='Iris-setosa')
plt.scatter(x[predictions==1,0],x[predictions==1,1],s=25,c='blue',label='Iris-versicolour')
plt.scatter(x[predictions==2,0],x[predictions==2,1],s=25,c='green',label='Iris-virginica')

#plotting the cluster's center
plt.scatter(model.cluster_centers_[:,0],model.cluster_centers_[:,1],s=100,c='yellow',label='Centroids')
plt.legend()
plt.grid()
plt.show()

sns.pairplot(df, hue='Species')
plt.suptitle("Pairplot of Iris Dataset", y=1.02)
plt.show()

df.hist(figsize=(10, 8), bins=20, edgecolor='black')
plt.suptitle("Histograms of Iris Dataset Features", y=1.02)
plt.tight_layout()
plt.show()

plt.figure(figsize=(8, 6))
sns.heatmap(iris_df.corr(), annot=True, cmap='twilight', fmt='.2f')
plt.title('Correlation Heatmap')
plt.show()

df.boxplot(by='Species', figsize=(10,6))
plt.title("Boxplot of Iris Dataset Features by Species")
plt.suptitle("")  # Removing default title
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
plt.xlabel('Species')
plt.ylabel('Measurement')
plt.tight_layout()
plt.show()
